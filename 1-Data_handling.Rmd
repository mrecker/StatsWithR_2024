# Data handling

```{r, echo=F, warning=F, message=F}
library(tidyverse)
```

## Importing data {-}

An essential part of data analysis is the ability to read (and store) external datasets. There are a myriad of different ways this can be done in R, partially depending on the file type / software originally used to store the data. Here we focus on three different file formats:

  - CSV files (*filename*.csv)
  - Excel files (*filename*.xls or *filename*.xlsx)
  - R data format (*filename*.rds or *filename*.RData)

The main difference between the approaches is that an `Rds` file stores data in a (R specific) binary format, meaning that you need R to read it. The same goes for Excel files. CSV files, in comparison, are (human readable) text files that can be opened by a number of different programs. In fact, on most operating systems, these are opened by Excel or a text editor by default. The decision which approach you should use often depends on whether you are the only one working with the data or whether you like the added benefit of viewing (or manipulating) data outside the R environment.

> **Note:** Excel is known to occasionally cause havoc with data (mostly due to it changing data types by itself), we are urging caution when handling Excel files. Always check the validity of your data before starting with your analysis!

--- 

### CSV files {-}

CSV (Comma-Separated Values) is a widely used data format separating values with commas or other delimiters (e.g. semi-colon or tab). 

There are different function pairs for reading CSV files, such as the inbuilt `read.table()` or `read.csv()`, and their equivalent functions for writing CSV files. Here we will use the `read_csv()` function, which is part of the `readr` package (included in `tidyverse`). Note: this function is strictly for comma-separated files, `read_csv2()` reads semicolon-separated and the `read_delim()` function reads files with any separating character; for full fucntion details, see [here] (https://www.rdocumentation.org/packages/readr/versions/2.1.5/topics/read_delim). 

As an example we will be using the `tobacco.csv` file that contains a simulated dataset on tobacco use and health of 1000 individuals. Please make sure that the file is contained in your current working directory.

```{r}
tobacco <- read.csv('tobacco.csv')
```

Check if this worked by printing out the first 5 rows

```{r}
head(tobacco, n = 5)
```

In an equivalent fashion we can save data in CSV format using the `write_csv()` function.

```{r}
# make sure you do not overwrite the original data file!!
write_csv(tobacco, "myData.csv")  
```

--- 

### Excel files {-}

Although we discourage the use of Excel for data handling, it is still one of the most common methods for storing data. We therefore briefly show you one method of how to read Excel files using the `read_excel` function from the `readxl` package. NOTE: although `readxl` will be installed as part of tidyverse, you will still need to load it explicitly, because it is not a core tidyverse package.

```{r}
# load library
library(readxl)

# read in excel data file
tobaccoXLS <- read_excel('tobacco.xlsx')

# print first few rows
head(tobaccoXLS, n = 5)
```

This functions offers a great deal of flexibility, from specifying which sheet to import (by default it will import the first one), specifying the data range, or *repairing* column names for easier downstream analysis.

```{r}
# specify the name of the sheet and only load the first 100 rows and 7 columns
tobaccoXLS <- read_excel('tobacco.xlsx', sheet = 'tobacco_2', range = 'A1:G101')

## which is equivalent to
# dat <- read_excel('tobacco.xlsx', range = 'tobacco_2!A1:G101')

# check the first 5 rows
head(tobaccoXLS, n = 5)
```

We can see that two column names contain spaces, which can make life a bit tricky during subsequent operations. For this, `read_excel` provides a `.name_repair` argument, that ensures column names will be syntactic (not containing special characters or reserved words) and work everywhere. (Note: this argument can also be used in the `read_csv()` function.)

```{r}
tobaccoXLS <- read_excel('tobacco.xlsx', 
                         sheet = 'tobacco_2', 
                         range = 'A1:G101', 
                         .name_repair = 'universal')

head(tobaccoXLS, n = 5)
```

A really handy cheatsheet for importing data with the tidyverse can be found [here](https://github.com/rstudio/cheatsheets/blob/main/data-import.pdf) 

--- 

### R data files {-}

To demonstrate the use of R data file format, we go the other way around and start by saving our `tobacco` dataframe as an R object.

```{r}
saveRDS(tobacco, file = 'tobacco.Rds')
```

> **Note:** the file will be saved in your current working directory. If you want to save it in a different folder you need to provide the full file path, e.g. `saveRDS(df, file = '.../StatsWithR//Data/myData.Rds')`.

Loading the data is equally simple:

```{r, output.lines=10}
# first we remove the tobacco data object to make sure everything works
rm(tobacco)

# load the data
readRDS('tobacco.Rds')
```

At first sight this looks like it has worked. However, you might also have noticed that there is no newly created object in your global environment. This means, although R successfully loaded the data, it was not assigned to an object and essentially lost; this is one of the key differences between `saveRDS`/`readRDS` and `save`/`load` (see below)). We therefore need to assign the read-in data to an object

```{r}
# read data and assign to an object called tobacco
tobacco <- readRDS('tobacco.Rds')

# see if it works
head(tobacco)
```

An alternative way is the use of the `Rdata` file format. 

```{r}
# save our dataframe in Rdata format
save(tobacco, file = "tobacco.Rdata")  

# remove from our environment
rm(tobacco)

# load the data
load("tobacco.Rdata")
```

As you will have noticed, in this case we do not need to explicitly assign the loaded data to object; instead, the original name of the dataframe will be used. Another advantage of using this format is that we can save multiple objects at once

```{r}
# save both dataframe in one file
save(tobacco, tobaccoXLS, file = 'tobacco_datasets.Rda')

# remove from environment
rm(tobacco, tobaccoXLS)

# load the data
load('tobacco_datasets.Rda')
```


One of the advantages of saving data in an R data format is that it is more space efficient. By default, `saveRDS()` (or `save()`) compresses the data, which can significantly shrink the size of the stored data. On the downside, it can also take a bit longer to load the data subsequently.

--- 

---

## Data types {-}

Although we assume that you are likely already familiar with different types of data, this is just a reminder of the most common data types in R 

  - numeric / integer
  - character
  - factor
  - logical

We have already come across some of them when we imported the `tobacco` data in the previous section. To check what types of data are contained in this dataset we can use the `class()` function; for example

```{r}
# get the data type of column 'gender'
class(tobacco$gender)

# get the data type of column 'BMI'
class(tobacco$BMI)
```

Instead of doing this for every column separately, we can apply this function across the whole dataframe with `sapply`

```{r}
sapply(tobacco, class)
```


Here's a brief overview of what these data types are and what they are generally used for.

### Numeric / integer {-}

A variable will be automatically stored as *numeric* data if the values are numbers or contain decimals. Depending on the function used to import data, a variable can also be assigned explicitly as *integer* if it does not contain any decimals. 

```{r}
# define a vector of three numerical values
x <- c(4, 3, 5)

# get the data type
class(x)

# compare to the imported data column 'age'
class(tobacco$age)
```

We can also *force* R to convert a numeric variable into an integer, and vice versa  

```{r}
x <- as.integer(x)
class(x)

tobacco$age <- as.numeric(tobacco$age)
class(tobacco$age)
```

---

### Character {-}

Character is the general data type to store text (strings), such as words, sentences etc. 

```{r}
# first example
a <- "this is a character data type"
class(a)

# second example
b <- "1"  # enclosing a number in quotes will define it as a character type
class(b)

# type conversion from numeric to character
c <- 12.3
d <- as.character(c)
class(d)

# automatic 'conversion'
v <- c(1, 2, 3, "4")  
class(v)

```

---

### Factor {-}

At a first glance, factor variables look very similar to character types. However, factors are used to denote *categorical* variables, i.e. those that can only take a (pre-determined) limited number of values. 

```{r}
# convert v into a categorical variable
f1 <- factor(v)

# printing it will already reveal the difference to v as the factor levels are provided alongside the values
f1

# this works also on numeric variables
f2 <- factor(c(1, 2, 3, 4))
f2
```

Looking at our tobacco dataframe we can see that some columns denote categorical variables (gender, age group, smoker, diseased and disease) and should be converted accordingly, which can be done either using the function `as.factor()` or just `factor()`. Here we will use `dplyr`'s `mutate()` function to convert all five columns simultaneously.
```{r}
tobacco <- tobacco %>%
  mutate(gender = factor(gender),
         age.gr = factor(age.gr),
         smoker = factor(smoker),
         diseased = factor(diseased),
         disease = factor(disease))

# check if this worked
sapply(tobacco, class)
```

---

### Logical {-}

Logical variables can only take on two values> `TRUE` and `FALSE` (which can also be abbreviated as `T` and `F`, respectively). These are common data types when used with logical operation, e.g.
```{r}
x <- 5
y <- 7

x > y  # read is 'is x greater than y'
```
or 
```{r}
if(x > y){
  print("x is greater than y")
}else{
  print("x is not greater than y")
}
```

Furthermore, a logical TRUE can be numerically interpreted as 1 and a FALSE as 0. 
```{r}
as.integer(x < y)
```

This fact can be used in a variety of cases, as shown in the example below (try to understand what exactly is going on)
```{r}
# define a vector with 15 elements 
v <- c(2, 6, 4, 8, 7, 8, 4, 1, 5, 8, 2, 9, 11, 4, 7)

# are the elements less than or equal to 5
v <= 5

# how many elements are less than or equal to 5 
sum(v <= 5)
```

---

## Missing data {-}

More often than not we will find ourselves confronted with datasets that are not complete. That is, some information might be missing for some of the variables, and we need to find a way to deal with those cases. In R, missing values are usually represented by `NA`. Note: when importing data we can specify the value or symbol used to represent missing data.

We can test for the presence of missing values using the `is.na()` function
```{r}
v <- c(1, 4, 2, NA, 8, 9)
is.na(v)
```
which confirms that there is a missing number between elements 3 and 5. To find the exact location we could use 
```{r}
which(is.na(v))
```

The `is.na()` function can also be applied to data frames, as shown below 
```{r, output.lines=10}
is.na(tobacco)
```
and in combination with some other functions can be used to get crucial information about the degree of *missingness* in our data
```{r}
# count the number of missing entries in each column and convert to percentage
100 * colSums(is.na(tobacco)) / nrow(tobacco) 
```

The big question always comes down to how to deal with missing data. The easiest approach is to just delete / ignore those cases, and there are two commonly used ways of doing this, with `na.omit()` or `complete.cases()`. The first function returns an object with all missing values removed
```{r}
# create a new data frame based on tobacco with all rows removed that contain NAs
tobacco_noNAs <- na.omit(tobacco)
head(tobacco_noNAs, 10)
```

The other option is to use the `comple.cases()` function, which returns a logical vector indicating which rows contain no missing values (returned as `TRUE`)
```{r, output.lines = 10}
complete.cases(tobacco)
```
and this can then be used to *subset* the data, i.e. we select only those rows that have full information for all variables
```{r}
tobacco_noNAs <- tobacco[complete.cases(tobacco),]
head(tobacco_noNAs, 10)
```

Although this works, there are two major issues with this approach

  - data loss
  - data bias
  
If you compare the original dataset with the reduced one you will notice two things: first, it is much smaller (203 observations compared to 1000), which is a reduction by over 70% even though only one of the variables contains more than 4% missing data; and second, the data now only contains observation of those individuals who are diseased, which would obviously bias our downstream analysis. Omitting missing data should thus only be done in exceptional circumstances and with great caution.

The safer, alternative strategies are either *data imputation*, which essentially tries to *guess* the missing values based on other information contained in the data (this is not covered as part of this workshop, but if you are interested you could have a look at [this site](https://www.r-bloggers.com/2023/01/imputation-in-r-top-3-ways-for-imputing-missing-data/)), or simply *ignoring* the missing data and relying on the fact that most R functions have their own way of dealing with missing values; e.g. compare  
```{r}
# sum over all elements in v produces NA
sum(v)
```
with
```{r}
# telling sum() to ignore, or remove NA's, solves this issue
sum(v, na.rm = TRUE)
```

**Beware:** different functions have different default settings when it comes to handling NA's; always look in the help file to make sure they do what you want them to do!

---


