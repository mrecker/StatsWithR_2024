## Data wrangling {-}

*Data wrangling*, or the process of cleaning and manipulating data for subsequent analysis, is a key component of modern statistical science and is becoming more important in the age of big (e.g. *high throughput*) data. The `tidyverse` incorporates a suite of packages, such as `tidyr` and `dplyr` that are designed to make common data wrangling tasks not only easier to achieve, but also easier to decipher. Readability of the code is at the core of the philosophy underpinning these packages.

> As always, there are plenty of resources to find useful information about the various data handling functions in the different `tidyverse` packages, including the [Data Import Cheat Sheet](https://github.com/rstudio/cheatsheets/raw/master/data-import.pdf) and [Data Transformation Cheat Sheet](https://github.com/rstudio/cheatsheets/raw/master/data-transformation.pdf).


If you haven't done so already, we first need to load the `tidyverse` library as well as the life expectancy dataset we introduced earlier.

```{r}
# load tidyverse
library(tidyverse)

# load dataset andassign to object LifeExp
LifeExp <- read.table('LifeExpectancyData.csv', sep = ',', header = T)
```


### Tidy data {-}

The architect behind the tidyverse, Hadley Wickham, distinguishes between two types of data set: *tidy* and *messy*. Rather than being pejorative towards different ways in which people store and visualise data, the point here is to make a distinction between a specific way of arranging data that is useful to most R analyses, and anything else. In fact Hadley has a neat analogy to a famous Tolstoy quote:

> "Tidy datasets are all alike but every messy dataset is messy in its own way." — Hadley Wickham

In this context, a tidy data set is one in which:

  - rows contain different observations
  - columns contain different variables
  - cells contain values
  

Let's look at a simple example using the life expectancy data.

```{r}
head(LifeExp)
```

```{task, title = "Question"}
Is this data *tidy*?
```

```{solution}
Yes, because each row corresponds to a single observation, each column corresponds to a single variable and each cell contains a value. 
```

$~$

In this workshop we will see various ways in which datasets can be manipulated to and from the *tidy* format.


### Filter rows {-}

The first data manipulation we could do is to filter the data, as we have done earlier when plotting the data only for the year 2000. In base R this worked as

```{r, eval=F}
LifeExp[LifeExp$Year == 2000,]
```

To do the equivalent in `tidyverse`, we use the `filter()` function

```{r, eval=F}
filter(LifeExp, Year == 2000)
```

Note, one of the most distinctive / useful feature of `tidyverse` (or rather `migrittr`, which `tidyverse`/`dplyr` depends on) is the so-called piping operator, denoted as `%>%`. This operator allows you to *chain* one function after another without relying on nested parentheses or having to assign / store intermediate objects. So what it is doing is evaluating the expression on the right-hand side (or next line) of the `%>%` (pipe) using the expression on the left (or same line) as the first argument. If this sounds confusing then fear not - all will be made clearer once you see it in action! Using the same example as above we can get the same results with piping

```{r, eval=F}
LifeExp %>% filter(Year == 2000)
```

Initially this might look more complicated but you will soon see how this is a very useful operator indeed.


### Sort rows {-}

Another common operation is to sort rows according to some criterion. For example, we might wish to sort our data by `Status` and then `Life.expectancy`. In tidyverse this is done using the `arrange()` function.

```{r, eval=F}
arrange(LifeExp, Status, Life.expectancy)
```

or using the piping operator

```{r, eval=F}
LifeExp %>% arrange(Status, Life.expectancy)
```


### Select columns {-}

The next common operation is the selection of columns, which also includes *de*selection of particular columns. Let's say we are interested only in the countries and their corresponding life expectancy, GDP, population size and the year of sampling. Before showing you how this can efficiently done in `tidyverse`, here are some options of how to achieve this in base R

```
## option 1
LifeExp[, match(c("Country", "Life.expectancy", "GDP", "Population"), colnames(LifeExp))]

## option 2
cbind(Country = LifeExp$Country, Life.expectancy = LifeExp$Life.expectancy, 
      GDP = LifeExp$GDP, Population = LifeExp$Population)

## option 3 (requires knowing which columns are which)
LifeExp[, c(1, 4, 16, 17)]
```

And here is how easy and hopefully by now intuitively this can be done using the `select()` function

```{r}
LifeExp %>% select(Country, Continent, Life.expectancy, GDP, Population) %>% head()
```

> **Note:** notice that we added one extra pipe at the end `%>% head(.)`. Remember that the `head()` function displays the first few rows of a data.frame. What we are doing here is that we first take the data.frame `LifeExp`, the apply the `filter()` function and then use the results of this as the argument in `head()` 

De-selection, or filtering out particular columns follows a similar structure but in this case the column to be removed is preceded by a '-'; for example

```{r, eval=F}
LifeExp %>% select(-Adult.Mortality) %>% head()
```

As you will have noticed, we can easy combine various data manipulation functions using pipes without having to store any intermediate results or use excessive parenthesis. Let's try this out

```{r}
LifeExp %>% 
    filter(Year == 2000) %>%
    select(Country, Continent, Life.expectancy, GDP, Population) %>%
    arrange(Life.expectancy) %>%
    head(n = 10)
```

Powerful stuff!


### Grouping and summarising {-}

A common thing we might want to do is to produce summaries of some variable for different subsets of the data. For example, we might want to produce an estimate of the mean life expectancy for for each year. The `dplyr` package provides a function `group_by()`, which allows us to group data by one or more variables, and the `summarise()`, which allows us to summarise data. These can be used in combination get stratified summaries as shown here

```{r}
LifeExp %>% 
    group_by(Year) %>%
    summarise(mn = mean(Life.expectancy))
```

The most commonly functions used for summarising data are

  - Center: `mean()`, `median()`
  - Spread: `sd()`, `IQR()`
  - Range: `min()`, `max()`,
  - Count: `n()`


```{task}
Test your skills by

  1. calculating the mean life expectancy by continent
  2. calculating the mean life expectancy by continent and year
  3. calculating the mean and median of the GDP for each continent in the years 2000, 2005 and 2010

(note, for both the `mean()` and `median()` we have to add an extra argument `na.rm = TRUE` - what happens if we don't?)
```

```{solution}

  1. calculating the mean life expectancy by continent

``{r}
LifeExp %>% 
    group_by(Continent, Year) %>%
    summarise(mn = mean(Life.expectancy))
``

  2. calculating the mean life expectancy by continent and year

``{r}
LifeExp %>% 
    group_by(Continent) %>%
    summarise(mn = mean(Life.expectancy))
``

  3. calculating the mean and median of the GDP for each continent in the years 2000, 2005 and 2010

``{r}
LifeExp %>% 
    filter(Year %in% c(2000, 2005, 2010)) %>%
    group_by(Year) %>%
    summarise(GDP_mn = mean(GDP, na.rm = T),
              GDP_md = median(GDP, na.rm = T))
``

```

$~$

### Reshaping datasets {-}

Recall, a key philosophy of `tidyverse` is the notion of data being *tidy*. In fact, to get the most out of `ggplot`, datasets need to be in a specific format. More often than not, though, you will be dealing with *untidy* data. To give you an example, let's have a look at the data file `ExposureIndex.csv`, which contains the recorded malaria exposure index for 103 individuals in Junju, Kenya, between the years 2000 and 2010.

```{r}
EI <- read.csv('ExposureIndex.csv', check.names = F)  # the argument check.names=F prevents renaming of col names
head(EI)
```


```{task, title = 'Question'}
Is this data in *tidy* format? And if not, why not?
```

```{solution}
No, this data is not in *tidy’ format. We can see that each row corresponds to a different participant, but each column corresponds to a different year. For this to be *tidy*, we would need one column containing the participant, one column containing the year, and a third column containing the exposure index for participant in each year.
```

$~$

Luckily, within `tidyverse` is it easy to *reshape* data to get it into the desired format. In this case we want to reshape it from a *wide format* into a *long format*. The necessary function to do this is called `gather()`, which takes two or more columns and gathers them into key-value pairs (here: year - exposure index). The columns to gather are `2000`, `2001`, ..., `2010`, which we can shorten to `2000:2010` (i.e. all columns from `2000` to `2010`)

```{r}
EI_long <- EI %>%
    gather(Year, ExposureIndex, '2000':'2010') 

head(EI_long, n = 10)
```

> **Note:** because the column names were numerical values and not strings, we have to encase them by ' '. This is not necessary if column names are in character format.


The converse of `gather()` is `spread()`, which takes two columns (`key` and `value`) and spreads them into multiple columns (dictated by the number of unique `values`). 

```{r}
EI_long %>%
    spread(Year, ExposureIndex) %>%
    head()
```


### Mutate {-}

Last but not least we show you how to create, modify or even delete columns with `mutate()`. In fact, `mutate()` is probably one of the functions you will end up using the most. However, the functionality of `mutate()` is introduced here by means of two examples, which also introduce a few other useful features.

In the first example we are going to create a new column in our data.frame `EI_long`, where we categorise the exposure index into *high* and *low* depending on its value being above or below 0.5, respectively. One new function we are going to introduce is `ifelse()`; please use the help for more details, although its use should become apparent.

```{r}
EI_long <- EI_long %>%
    mutate(EI_cat = ifelse(ExposureIndex >= 0.5, 'high', 'low'))

head(EI_long, n=10)
```


In the second example we going to use `mutate()` to modify three existing columns. First, we are going to round the `ExposureIndex` to two significant digits; then we are turning our new column `EI_cat` into a categorical variable using the function `factor()`; and finally we are going to change the `Year` column into a numeric format 

```{r}
EI_long <- EI_long %>%
    mutate(ExposureIndex = round(ExposureIndex, digits=2)) %>%
    mutate(EI_cat = factor(EI_cat)) %>%
    mutate(Year = as.numeric(Year))

# note, we could have done the same in a single mutate() call
# EI_long <- EI_long %>%
#     mutate(ExposureIndex = round(ExposureIndex, digits=2),
#            EI_cat = factor(EI_cat),
#            Year = as.numeric(Year))

head(EI_long, n=10)
```

```{task}

  1. produce a `ggplot` line graph of the mean exposure index against time (2000 to 2010)
  2. show the distribution of the expsoure index over time by means of box-and-whisker plots

``{info, title = 'Hint'}
Hint: the first task involves a combination of `group_by()` and `summarise()`, and for the second task you might need to mutate the `Year` column into a categorical variable. Also, you can do this by either creating a new data.frame for each task, or by using the pipe to send your modified data.frame straight to `ggplot`, in which case you do not need to specifiy the data in the `ggplot()` function.
``

```

```{solution}

  1. a line graph of the mean exposure index against time (2000 to 2010)

``{r}
EI_long %>%
    group_by(Year) %>%
    summarise(meanEI = mean(ExposureIndex)) %>%
    ggplot(aes(x = Year, y = meanEI)) +
    geom_line()
``

  2. distribution of the expsoure index over time by means of box-and-whisker plots

``{r}
EI_long %>%
    mutate(Year = factor(Year)) %>%
    ggplot(aes(x = Year, y = ExposureIndex)) +
    geom_boxplot()
``

```

$~$

### Dealing with missing data {-}

One recurring problem with data analysis is that data are often incomplete, leading to more or less serious downstream data analysis problems. That is, different functions deal with missing data in different ways, some simply ignore them whereas others fail completely. We therefore need to expand our data wrangling toolbox.

Missing data in R are usually referred to `NA`'s, and here is an example of where NA's can become problematic

```{r}
x = c(1, 4, 2, 9, NA, 4, 5)
mean(x)
```

There are various ways to deal with missing data, of which we only touch upon a few

#### **Detecting missing data** {-}

The first thing we might want to know if there are any NA's, and a function for this is `is.na()`, which works on single variables, vectors, matrices and data.frames

```{r}
df <- data.frame(x = c(1, 4, 2, 9, NA, 4, 5),
                 y = c(0.2, 0.5, NA, 0.1, NA, 0.8, 0.9))

is.na(df)
```

#### **Removing NA's** {-}

Going back to our previous example, if we want to calculate the mean of `x` we can either manually remove the offending entries or tell `mean()` to ignore them 

```{r}
# option 1: tell mean() to ignore NA
mean(x, na.rm = TRUE)

# option 2: remove NA manually
x <- x[!is.na(x)]  # this means that x should be assigned to all entries of x that are not (!) NA
mean(x)
```

What about our data.frame `df`? As `df` has both rows and columns we cannot simply use the same method but have to be more specific. For example, to remove a row where `df$x` contains missing data

```{r}
df[!is.na(df$x),]
```

or to remove all rows where either `df$x` *or* `df$y` contains missing data (note: for this we need a logical operator, which is in fact an *and*, `&`, because we neither want NA's in `x` nor in `y` so both conditions have to be safisfied together)

```{r}
df[!is.na(df$x) & !is.na(df$y),]
```

An easier way to achieve the same is by using the `complete.cases()` function, which selects only those rows where we have complete information (i.e. no missing data) 

```{r}
df[complete.cases(df),]
```

And finally here the same examples but done using `tidy` functionality

```{r}
df %>%
    filter(!is.na(x) & !is.na(y))
```

which is equivalent to 

```{r}
df %>%
    drop_na()
```

which is equivalent to 

```{r}
df %>% 
  filter_at(vars(x:y), all_vars(!is.na(.)))
```

which is equivalent to

```{r}
df %>% 
  filter_at(vars(x:y), all_vars(complete.cases(.)))
```

As they say in English: *"there is more than one way to skin a cat"*.


